{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-30T15:06:23.440732Z",
     "start_time": "2025-05-30T15:06:03.829032Z"
    }
   },
   "source": [
    "import time\n",
    "import string, json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NLTK setup",
   "id": "2fe107dc95743a85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T15:06:23.783694Z",
     "start_time": "2025-05-30T15:06:23.467758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('punkt',   quiet=True)\n",
    "nltk.download('stopwords',quiet=True)\n",
    "nltk.download('wordnet', quiet=True)"
   ],
   "id": "20a8cd6725290136",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading datasets",
   "id": "dd7a92c302247ee6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T15:06:25.231639Z",
     "start_time": "2025-05-30T15:06:24.787646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "COLLECTION_PATH     = '../subtask4b_collection_data.pkl'\n",
    "TRAIN_QUERY_PATH    = '../subtask4b_query_tweets_train.tsv'\n",
    "DEV_QUERY_PATH      = '../subtask4b_query_tweets_dev.tsv'\n",
    "OUT_TRAIN_PRED_PATH = 'predictions_train.tsv'\n",
    "OUT_DEV_PRED_PATH   = '../predictions_dev.tsv'\n",
    "\n",
    "df_col   = pd.read_pickle(COLLECTION_PATH)\n",
    "df_train = pd.read_csv(TRAIN_QUERY_PATH, sep='\\t', dtype={'post_id':str})\n",
    "df_dev   = pd.read_csv(DEV_QUERY_PATH,   sep='\\t', dtype={'post_id':str})"
   ],
   "id": "92033c9f9a6dd08f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preprocessing + unigram & bigram tokenizer",
   "id": "c877a10958a90a92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T15:06:25.263645Z",
     "start_time": "2025-05-30T15:06:25.243643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize_and_ngrams(text: str):\n",
    "    txt = (text or '').lower().translate(\n",
    "        str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    tokens = [\n",
    "        lemmatizer.lemmatize(tok)\n",
    "        for tok in nltk.word_tokenize(txt)\n",
    "        if tok.isalpha() and tok not in stop_words\n",
    "    ]\n",
    "    bigrams = [f\"{tokens[i]}_{tokens[i+1]}\" for i in range(len(tokens)-1)]\n",
    "    return tokens + bigrams"
   ],
   "id": "fb7fad986a1d0d4d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Build the BM25 corpus: title×2 + abstract",
   "id": "5cff048b8c55b6d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T15:06:40.443450Z",
     "start_time": "2025-05-30T15:06:25.455641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "titles    = df_col['title'].fillna('').tolist()\n",
    "abstracts = df_col['abstract'].fillna('').tolist()\n",
    "uids      = df_col['cord_uid'].tolist()\n",
    "\n",
    "bm25_corpus = []\n",
    "for t,a in zip(titles, abstracts):\n",
    "    t_toks = tokenize_and_ngrams(t)\n",
    "    a_toks = tokenize_and_ngrams(a)\n",
    "    bm25_corpus.append(t_toks*2 + a_toks)  # title-boost ×2"
   ],
   "id": "256ae5a9f0d3bb5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initialize BM25 with tuned params",
   "id": "df1c36515db007ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T15:06:42.203611Z",
     "start_time": "2025-05-30T15:06:40.478195Z"
    }
   },
   "cell_type": "code",
   "source": "bm25 = BM25Okapi(bm25_corpus, k1=1.0, b=0.9)",
   "id": "59e2a7fa16eeb28c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Retrieval function (top-5)",
   "id": "73f59169f19d3eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T15:06:42.250599Z",
     "start_time": "2025-05-30T15:06:42.237604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_top5(text: str):\n",
    "    q_toks = tokenize_and_ngrams(text)\n",
    "    scores = bm25.get_scores(q_toks)\n",
    "    top5   = np.argsort(scores)[::-1][:5]\n",
    "    return [uids[i] for i in top5]"
   ],
   "id": "8dcfc82632bd749f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run + evaluate function",
   "id": "1aa6b7904f29fd63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T15:06:42.296597Z",
     "start_time": "2025-05-30T15:06:42.284596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_and_evaluate(df, split_name, out_path):\n",
    "    # 8.1 Generate predictions and measure time\n",
    "    print(f\"▶ [{split_name}] Retrieving for {len(df)} queries…\")\n",
    "    start = time.perf_counter()\n",
    "    df['preds'] = df['tweet_text'].map(lambda q: json.dumps(retrieve_top5(q)))\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"  • Retrieval & write took {elapsed:.2f}s\")\n",
    "\n",
    "    df[['post_id','preds']].to_csv(\n",
    "        out_path, sep='\\t', index=False, quoting=csv.QUOTE_MINIMAL\n",
    "    )\n",
    "\n",
    "    # Compute MRR@5 & Top-1\n",
    "    rr_sum, top1 = 0.0, 0\n",
    "    for _, row in df.iterrows():\n",
    "        true = row['cord_uid']\n",
    "        pred = json.loads(row['preds'])\n",
    "        if true in pred:\n",
    "            pos = pred.index(true) + 1\n",
    "            rr_sum += 1.0/pos\n",
    "            top1  += (pos == 1)\n",
    "    n = len(df)\n",
    "    mrr5 = rr_sum / n\n",
    "    acc1 = top1  / n\n",
    "    print(f\"▶ [{split_name}] MRR@5 = {mrr5:.3f}, Top-1 = {acc1:.3f}\\n\")\n",
    "    return elapsed, mrr5, acc1"
   ],
   "id": "19b9f265ec0399ad",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Execute for train & dev",
   "id": "19de2c4ab2012446"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-30T15:06:42.331605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_time, train_mrr, train_acc1 = run_and_evaluate(\n",
    "    df_train, 'TRAIN', OUT_TRAIN_PRED_PATH\n",
    ")\n",
    "dev_time, dev_mrr, dev_acc1       = run_and_evaluate(\n",
    "    df_dev,   'DEV',   OUT_DEV_PRED_PATH\n",
    ")"
   ],
   "id": "96ecd957db32f295",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ [TRAIN] Retrieving for 12853 queries…\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Summary",
   "id": "6a141856edad7a19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"=== Summary ===\")\n",
    "print(f\"TRAIN: time={train_time:.2f}s, MRR@5={train_mrr:.3f}, Top-1={train_acc1:.3f}\")\n",
    "print(f\"  DEV: time={dev_time:.2f}s,   MRR@5={dev_mrr:.3f}, Top-1={dev_acc1:.3f}\")"
   ],
   "id": "308e966150643b2a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
