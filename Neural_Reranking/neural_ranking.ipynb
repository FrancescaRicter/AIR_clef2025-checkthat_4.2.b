{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Re-Ranking Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: rank_bm25 in /opt/conda/lib/python3.11/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rank_bm25) (1.26.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting sentence-transformers==4.0.0\n",
      "  Using cached sentence_transformers-4.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers==4.41.0\n",
      "  Using cached transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting huggingface-hub==0.19.4\n",
      "  Using cached huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==4.0.0) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==4.0.0) (2.1.2+cu121)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==4.0.0) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==4.0.0) (1.15.1)\n",
      "INFO: pip is looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Cannot install huggingface-hub==0.19.4 and sentence-transformers==4.0.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    The user requested huggingface-hub==0.19.4\n",
      "    sentence-transformers 4.0.0 depends on huggingface-hub>=0.20.0\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.11/site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.45.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (2.1.2+cu121)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: tensorflow 2.14.0\n",
      "Uninstalling tensorflow-2.14.0:\n",
      "  Successfully uninstalled tensorflow-2.14.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping tf_keras as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorflow==2.14.0\n",
      "  Using cached tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (4.25.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (1.65.5)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.14.0) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n",
      "Using cached tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tensorflow\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed tensorflow-2.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mName: sentence-transformers\n",
      "Version: 4.1.0\n",
      "Summary: Embeddings, Retrieval, and Reranking\n",
      "Home-page: https://www.SBERT.net\n",
      "Author: \n",
      "Author-email: Nils Reimers <info@nils-reimers.de>, Tom Aarsen <tom.aarsen@huggingface.co>\n",
      "License: Apache 2.0\n",
      "Location: /opt/conda/lib/python3.11/site-packages\n",
      "Requires: huggingface-hub, Pillow, scikit-learn, scipy, torch, tqdm, transformers, typing_extensions\n",
      "Required-by: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.2.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25\n",
    "\n",
    "!pip install sentence-transformers==4.0.0 transformers==4.41.0 huggingface-hub==0.19.4\n",
    "\n",
    "!pip install -U sentence-transformers\n",
    "\n",
    "!pip uninstall tensorflow tf_keras -y\n",
    "\n",
    "!pip install tensorflow==2.14.0\n",
    "\n",
    "!pip show sentence-transformers\n",
    "\n",
    "!pip install datasets\n",
    "\n",
    "!pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "LjI8XbeNYngc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import joblib\n",
    "from io import BytesIO\n",
    "import requests \n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sentence_transformers.cross_encoder import CrossEncoder, CrossEncoderTrainer, losses\n",
    "\n",
    "import random\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from sentence_transformers.cross_encoder.evaluation import (\n",
    "    CrossEncoderNanoBEIREvaluator,\n",
    "    CrossEncoderRerankingEvaluator,\n",
    ")\n",
    "\n",
    "from sentence_transformers.cross_encoder import (\n",
    "    CrossEncoder,\n",
    "    CrossEncoderModelCardData,\n",
    "    CrossEncoderTrainer,\n",
    "    CrossEncoderTrainingArguments,\n",
    ")\n",
    "\n",
    "from sentence_transformers.cross_encoder import CrossEncoderTrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the collection set\n",
    "The collection set contains metadata of CORD-19 academic papers.\n",
    "\n",
    "The preprocessed and filtered CORD-19 dataset is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "AIpO3O5saCwT"
   },
   "outputs": [],
   "source": [
    "uri = \"https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/raw/main/task4/subtask_4b/subtask4b_collection_data.pkl\"\n",
    "df_collection = joblib.load(BytesIO(requests.get(uri).content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dj6lfnIGaJCq",
    "outputId": "f1368a24-e6c9-49ab-cf47-90f18ba6e6f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7718 entries, 162 to 1056448\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   cord_uid          7718 non-null   object        \n",
      " 1   source_x          7718 non-null   object        \n",
      " 2   title             7718 non-null   object        \n",
      " 3   doi               7677 non-null   object        \n",
      " 4   pmcid             4959 non-null   object        \n",
      " 5   pubmed_id         6233 non-null   object        \n",
      " 6   license           7718 non-null   object        \n",
      " 7   abstract          7718 non-null   object        \n",
      " 8   publish_time      7715 non-null   object        \n",
      " 9   authors           7674 non-null   object        \n",
      " 10  journal           6668 non-null   object        \n",
      " 11  mag_id            0 non-null      float64       \n",
      " 12  who_covidence_id  528 non-null    object        \n",
      " 13  arxiv_id          20 non-null     object        \n",
      " 14  label             7718 non-null   object        \n",
      " 15  time              7715 non-null   datetime64[ns]\n",
      " 16  timet             7718 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(14)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_collection.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "5-FcrWlSaKmC",
    "outputId": "36dff88b-dc40-4a4b-ddb4-48deb660c3f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "      <td>10.1371/journal.pone.0002618</td>\n",
       "      <td>PMC2440799</td>\n",
       "      <td>18612429</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>BACKGROUND: Governments are preparing for a po...</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>van der Sande, Marianne; Teunis, Peter; Sabel,...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>1215561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>PMC</td>\n",
       "      <td>The Failure of R (0)</td>\n",
       "      <td>10.1155/2011/527610</td>\n",
       "      <td>PMC3157160</td>\n",
       "      <td>21860658</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The basic reproductive ratio, R (0), is one of...</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>Li, Jing; Blakeley, Daniel; Smith?, Robert J.</td>\n",
       "      <td>Comput Math Methods Med</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>1313452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "      <td>10.4103/0970-2113.99118</td>\n",
       "      <td>PMC3424870</td>\n",
       "      <td>22919170</td>\n",
       "      <td>cc-by-nc-sa</td>\n",
       "      <td>The pandemic of swine flu (H1N1) influenza spr...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Singh, Virendra; Sharma, Bharat Bhushan; Patel...</td>\n",
       "      <td>Lung India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1325376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>PMC</td>\n",
       "      <td>What was the primary mode of smallpox transmis...</td>\n",
       "      <td>10.3389/fcimb.2012.00150</td>\n",
       "      <td>PMC3509329</td>\n",
       "      <td>23226686</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The mode of infection transmission has profoun...</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>Milton, Donald K.</td>\n",
       "      <td>Front Cell Infect Microbiol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>1354147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Lessons from the History of Quarantine, from P...</td>\n",
       "      <td>10.3201/eid1902.120312</td>\n",
       "      <td>PMC3559034</td>\n",
       "      <td>23343512</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>In the new millennium, the centuries-old strat...</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>Tognotti, Eugenia</td>\n",
       "      <td>Emerg Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>1359849600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cord_uid source_x                                              title  \\\n",
       "162   umvrwgaw      PMC  Professional and Home-Made Face Masks Reduce E...   \n",
       "611   spiud6ok      PMC                               The Failure of R (0)   \n",
       "918   aclzp3iy      PMC  Pulmonary sequelae in a patient recovered from...   \n",
       "993   ycxyn2a2      PMC  What was the primary mode of smallpox transmis...   \n",
       "1053  zxe95qy9      PMC  Lessons from the History of Quarantine, from P...   \n",
       "\n",
       "                               doi       pmcid pubmed_id      license  \\\n",
       "162   10.1371/journal.pone.0002618  PMC2440799  18612429        cc-by   \n",
       "611            10.1155/2011/527610  PMC3157160  21860658        cc-by   \n",
       "918        10.4103/0970-2113.99118  PMC3424870  22919170  cc-by-nc-sa   \n",
       "993       10.3389/fcimb.2012.00150  PMC3509329  23226686        cc-by   \n",
       "1053        10.3201/eid1902.120312  PMC3559034  23343512        no-cc   \n",
       "\n",
       "                                               abstract publish_time  \\\n",
       "162   BACKGROUND: Governments are preparing for a po...   2008-07-09   \n",
       "611   The basic reproductive ratio, R (0), is one of...   2011-08-16   \n",
       "918   The pandemic of swine flu (H1N1) influenza spr...         2012   \n",
       "993   The mode of infection transmission has profoun...   2012-11-29   \n",
       "1053  In the new millennium, the centuries-old strat...   2013-02-03   \n",
       "\n",
       "                                                authors  \\\n",
       "162   van der Sande, Marianne; Teunis, Peter; Sabel,...   \n",
       "611       Li, Jing; Blakeley, Daniel; Smith?, Robert J.   \n",
       "918   Singh, Virendra; Sharma, Bharat Bhushan; Patel...   \n",
       "993                                   Milton, Donald K.   \n",
       "1053                                  Tognotti, Eugenia   \n",
       "\n",
       "                          journal  mag_id who_covidence_id arxiv_id     label  \\\n",
       "162                      PLoS One     NaN              NaN      NaN  umvrwgaw   \n",
       "611       Comput Math Methods Med     NaN              NaN      NaN  spiud6ok   \n",
       "918                    Lung India     NaN              NaN      NaN  aclzp3iy   \n",
       "993   Front Cell Infect Microbiol     NaN              NaN      NaN  ycxyn2a2   \n",
       "1053             Emerg Infect Dis     NaN              NaN      NaN  zxe95qy9   \n",
       "\n",
       "           time       timet  \n",
       "162  2008-07-09  1215561600  \n",
       "611  2011-08-16  1313452800  \n",
       "918  2012-01-01  1325376000  \n",
       "993  2012-11-29  1354147200  \n",
       "1053 2013-02-03  1359849600  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the query sets\n",
    "\n",
    "The query set contains tweets with implicit references to academic papers from the collection set.\n",
    "\n",
    "The preprocessed query set is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "rIFBMG28aMUM"
   },
   "outputs": [],
   "source": [
    "# Download the query tweets from the Gitlab repository: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b?ref_type=heads\n",
    "PATH_QUERY_TRAIN_DATA = 'https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/raw/main/task4/subtask_4b/subtask4b_query_tweets_train.tsv'\n",
    "PATH_QUERY_DEV_DATA = 'https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/raw/main/task4/subtask_4b/subtask4b_query_tweets_dev.tsv?inline=false'\n",
    "PATH_QUERY_TEST_DATA = 'https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/raw/main/task4/subtask_4b/subtask4b_query_tweets_test.tsv?ref_type=heads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "VBLDp0MeaOqk"
   },
   "outputs": [],
   "source": [
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')\n",
    "df_query_test = pd.read_csv(PATH_QUERY_TEST_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6VV7BNeQaQOq",
    "outputId": "617b99f7-660c-4a48-9810-8355c1736689"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>4kfl29ul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>jtwb17u8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Taiwan - a population of 23 million has had ju...</td>\n",
       "      <td>0w9k8iy1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Obtaining a diagnosis of autism in lower incom...</td>\n",
       "      <td>tiqksd69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid\n",
       "0        0  Oral care in rehabilitation medicine: oral vul...  htlvpvz5\n",
       "1        1  this study isn't receiving sufficient attentio...  4kfl29ul\n",
       "2        2  thanks, xi jinping. a reminder that this study...  jtwb17u8\n",
       "3        3  Taiwan - a population of 23 million has had ju...  0w9k8iy1\n",
       "4        4  Obtaining a diagnosis of autism in lower incom...  tiqksd69"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "akxdvhdhaS0u",
    "outputId": "0870a82f-d1c8-474c-d350-cb6a1d6c8c5c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid\n",
       "0       16  covid recovery: this study from the usa reveal...  3qvh482o\n",
       "1       69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu\n",
       "2       73  I recall early on reading that researchers who...  sts48u9i\n",
       "3       93  You know you're credible when NIH website has ...  3sr2exq9\n",
       "4       96  Resistance to antifungal medications is a grow...  ybwwmyqy"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A recent research study published yesterday cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"We should track the long-term effects of thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>the agony of \"long haul\" covid-19 symptoms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Home and online monitoring and assessment of b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>it may be a long one, folks! to avoid exceedin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text\n",
       "0        1  A recent research study published yesterday cl...\n",
       "1        2  \"We should track the long-term effects of thes...\n",
       "2        3        the agony of \"long haul\" covid-19 symptoms.\n",
       "3        4  Home and online monitoring and assessment of b...\n",
       "4        5  it may be a long one, folks! to avoid exceedin..."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 Baseline imports and methods\n",
    "The following code runs a BM25 baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(dataframe, field): \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def tokenize_and_stem(text):\n",
    "        tokens = word_tokenize(text)\n",
    "        filtered = [w for w in tokens if w.isalpha()]\n",
    "        lemmas = [lemmatizer.lemmatize(w) for w in filtered]\n",
    "        return ' '.join(lemmas) \n",
    "    \n",
    "    dataframe[field] = dataframe[field].str.lower()\n",
    "    \n",
    "    # Tokenize and stem\n",
    "    dataframe[field] = dataframe[field].apply(tokenize_and_stem)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_cord_uids(query):\n",
    "  text2bm25top = {}\n",
    "  if query in text2bm25top.keys():\n",
    "      return text2bm25top[query]\n",
    "  else:\n",
    "      tokenized_query = query.split(' ')\n",
    "      doc_scores = bm25.get_scores(tokenized_query)\n",
    "      indices = np.argsort(-doc_scores)[:5]\n",
    "      bm25_topk = [cord_uids[x] for x in indices]\n",
    "\n",
    "      text2bm25top[query] = bm25_topk\n",
    "      return bm25_topk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C28wDlS4fDgC"
   },
   "source": [
    "## Two-Stage Retriever Class: BM25 and Neural Re-Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "Q72hLr4Se_o0"
   },
   "outputs": [],
   "source": [
    "class NeuralRanker:\n",
    "    def __init__(self, model_name='BAAI/bge-reranker-large'):\n",
    "\n",
    "        self.model = CrossEncoder(model_name)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def rank_candidates(self, query, candidates, batch = 128):\n",
    "        \"\"\"Rerank candidates using neural model\"\"\"\n",
    "        all_scores = []\n",
    "\n",
    "        for i in range(0, len(candidates), batch):          \n",
    "            batch_candidates = candidates[i:i+batch]\n",
    "            pairs = [(query, cand_text) for cand_text in batch_candidates]\n",
    "    \n",
    "            batch_scores = self.model.predict(pairs) \n",
    "            all_scores.extend(batch_scores)\n",
    "           \n",
    "        return np.array(all_scores)\n",
    "\n",
    "    def rank(self, query, candidates, batch=128):\n",
    "        return self.rank_candidates(query, candidates, batch=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "V_eRzGVve_lY"
   },
   "outputs": [],
   "source": [
    "class TwoStageRetriever:\n",
    "    def __init__(self, bm25, df_collection, neural_ranker):\n",
    "         # Store components and initialize cache\n",
    "        self.bm25 = bm25\n",
    "        self.df_collection = df_collection\n",
    "        self.neural_ranker = neural_ranker\n",
    "        self.cord_uids = df_collection['cord_uid'].tolist()\n",
    "        self.text_cache = {}  \n",
    "\n",
    "    def get_document_text(self, cord_uid):\n",
    "        \"\"\"Efficient document text retrieval with caching\"\"\"\n",
    "        \"\"\"Get document text with caching\"\"\"\n",
    "        if cord_uid not in self.text_cache:\n",
    "            # Find document in collection\n",
    "            doc_row = self.df_collection[self.df_collection['cord_uid'] == cord_uid]\n",
    "            if not doc_row.empty:\n",
    "                # Combine title and abstract\n",
    "                self.text_cache[cord_uid] = f\"{doc_row.iloc[0]['title']} {doc_row.iloc[0]['abstract']}\"\n",
    "            else:\n",
    "                self.text_cache[cord_uid] = None\n",
    "        return self.text_cache[cord_uid]\n",
    "\n",
    "    def retrieve(self, query, preprocessing=False, top_k_bm25=50, top_k_final=5, batch = 128):\n",
    "        bm25_results = []\n",
    "        \n",
    "        \"\"\"Two-stage retrieval process\"\"\"\n",
    "        # First stage: BM25 retrieval\n",
    "        tokenized_query = query.split(' ')\n",
    "        doc_scores = self.bm25.get_scores(tokenized_query)\n",
    "        bm25_indices = np.argsort(-doc_scores)[:top_k_bm25]\n",
    "        candidate_uids = [self.cord_uids[i] for i in bm25_indices]\n",
    "        \n",
    "        # Get valid candidate texts\n",
    "        candidate_data = []\n",
    "        for uid in candidate_uids:\n",
    "            text = self.get_document_text(uid)\n",
    "            if text:\n",
    "                candidate_data.append((uid, text))\n",
    "\n",
    "        # Second stage: Neural reranking\n",
    "        # Return if no candidates found\n",
    "        if not candidate_data:\n",
    "            return []\n",
    "\n",
    "        uids, texts = zip(*candidate_data)\n",
    "        scores = self.neural_ranker.rank_candidates(query, texts, batch =batch)\n",
    "\n",
    "        # Combine and sort results\n",
    "        # Sort by descending scores and return top-k\n",
    "        sorted_indices = np.argsort(-scores)\n",
    "\n",
    "        return [(uids[i], scores[i]) for i in sorted_indices[:top_k_final]], candidate_uids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and Competition File Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5O6l4OaQp0Un",
    "outputId": "f77569a2-ef8e-482b-fb46-45d708ea11db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_submission(df_query, retriever, top_k_bm25, preprocessing=False, output_path=\"/submission.tsv\"):\n",
    "    \"\"\"Combined evaluation and submission generation\"\"\"\n",
    "    results = []\n",
    "    submission_data = []\n",
    "    bm25_docs = []\n",
    "\n",
    "    has_cord_uid = 'cord_uid' in df_query.columns\n",
    "\n",
    "    for idx, row in tqdm(df_query.iterrows(), total=len(df_query), desc=\"Processing queries\"):\n",
    "        # extract query data    \n",
    "        query = row['tweet_text']\n",
    "        if has_cord_uid:\n",
    "            true_uid = row['cord_uid']\n",
    "        post_id = row['post_id']\n",
    "\n",
    "        # Retrieve ranked results\n",
    "        ranked_results, bm25_results = retriever.retrieve(query, preprocessing, top_k_bm25)\n",
    "        predicted_uids = [uid for uid, _ in ranked_results]\n",
    "\n",
    "        #bm25 results\n",
    "        bm25_docs.append({\n",
    "            'post_id': post_id,\n",
    "            'preds': bm25_results\n",
    "        })\n",
    "\n",
    "        # Store submission data\n",
    "        top5_uids = predicted_uids[:10]\n",
    "        submission_data.append({\n",
    "            'post_id': post_id,\n",
    "            'preds': top5_uids\n",
    "        })\n",
    "\n",
    "        if has_cord_uid:\n",
    "            results.append({\n",
    "                'post_id': post_id,\n",
    "                'true_uid': true_uid\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                'post_id': post_id\n",
    "            })\n",
    "        \n",
    "\n",
    "    # Save files\n",
    "    submission_df = pd.DataFrame(submission_data)\n",
    "    submission_df.to_csv('submission.tsv', sep='\\t', index=False)\n",
    "    print(f\"Submission file saved to submission.tsv\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('results_df.tsv', sep='\\t', index=False)\n",
    "    print(f\"Submission file saved to results_df.tsv\")\n",
    "    \n",
    "    bm25_docs  = pd.DataFrame(bm25_docs)\n",
    "    bm25_docs.to_csv('bm25_docs.tsv', sep='\\t', index=False)\n",
    "    print(f\"Submission file saved to bm25_docs.tsv\")\n",
    "    \n",
    "    return results_df, submission_df, bm25_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(submission_df, results, col_gold, col_pred):\n",
    "    submission_df = submission_df.merge(\n",
    "    results[['post_id', 'true_uid']], on='post_id', how='left'\n",
    "    )\n",
    "    submission_df = submission_df.rename(columns={'true_uid': 'label'})\n",
    "\n",
    "    return get_performance_mrr(submission_df, 'label', 'preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine title and abstract for all the documents in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(df_queries, df_collection, reranker_model, top_k_bm25, preprocessing=False):\n",
    "    if preprocessing:\n",
    "        df_collection = data_processing(df_collection, 'title')\n",
    "        df_collection = data_processing(df_collection, 'abstract')\n",
    "\n",
    "        df_queries = data_processing(df_queries, 'tweet_text')\n",
    "\n",
    "    # Create the BM25 corpus\n",
    "    corpus = df_collection[:][['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "    cord_uids = df_collection[:]['cord_uid'].tolist()\n",
    "    tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "\n",
    "    # Initialize components\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    neural_ranker = NeuralRanker(reranker_model)\n",
    "    retriever = TwoStageRetriever(bm25, df_collection, neural_ranker)\n",
    "\n",
    "    results, submission_df, bm25_docs = generate_submission(\n",
    "    df_queries,\n",
    "    retriever,\n",
    "    top_k_bm25,\n",
    "    preprocessing\n",
    "    )\n",
    "\n",
    "    return results, submission_df, bm25_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-6-v2, Split=dev, Docs=20, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:26<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-6-v2, Split=dev, Docs=20, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:26<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-6-v2, Split=dev, Docs=30, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:32<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-6-v2, Split=dev, Docs=30, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:32<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-6-v2, Split=dev, Docs=50, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:41<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-6-v2, Split=dev, Docs=50, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:41<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-12-v2, Split=dev, Docs=20, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:31<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-12-v2, Split=dev, Docs=20, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:31<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-12-v2, Split=dev, Docs=30, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:43<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-12-v2, Split=dev, Docs=30, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:43<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-12-v2, Split=dev, Docs=50, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:59<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-MiniLM-L-12-v2, Split=dev, Docs=50, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:59<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-TinyBERT-L-6, Split=dev, Docs=20, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:36<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-TinyBERT-L-6, Split=dev, Docs=20, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:34<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-TinyBERT-L-6, Split=dev, Docs=30, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:42<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-TinyBERT-L-6, Split=dev, Docs=30, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:40<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-TinyBERT-L-6, Split=dev, Docs=50, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:56<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-TinyBERT-L-6, Split=dev, Docs=50, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:59<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-electra-base, Split=dev, Docs=20, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:48<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-electra-base, Split=dev, Docs=20, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:48<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-electra-base, Split=dev, Docs=30, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:07<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-electra-base, Split=dev, Docs=30, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:07<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-electra-base, Split=dev, Docs=50, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:40<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/ms-marco-electra-base, Split=dev, Docs=50, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:39<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/stsb-roberta-base, Split=dev, Docs=20, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:46<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/stsb-roberta-base, Split=dev, Docs=20, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:45<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/stsb-roberta-base, Split=dev, Docs=30, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:04<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/stsb-roberta-base, Split=dev, Docs=30, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:04<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/stsb-roberta-base, Split=dev, Docs=50, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:35<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=cross-encoder/stsb-roberta-base, Split=dev, Docs=50, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:35<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-base, Split=dev, Docs=20, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:47<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-base, Split=dev, Docs=20, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:46<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-base, Split=dev, Docs=30, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:03<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-base, Split=dev, Docs=30, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:05<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-base, Split=dev, Docs=50, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:36<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-base, Split=dev, Docs=50, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:37<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-large, Split=dev, Docs=20, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:54<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-large, Split=dev, Docs=20, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:54<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-large, Split=dev, Docs=30, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [02:42<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-large, Split=dev, Docs=30, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [02:41<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-large, Split=dev, Docs=50, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [04:24<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=BAAI/bge-reranker-large, Split=dev, Docs=50, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [04:23<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=ncbi/MedCPT-Cross-Encoder, Split=dev, Docs=20, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:44<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=ncbi/MedCPT-Cross-Encoder, Split=dev, Docs=20, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:44<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=ncbi/MedCPT-Cross-Encoder, Split=dev, Docs=30, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:01<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=ncbi/MedCPT-Cross-Encoder, Split=dev, Docs=30, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=ncbi/MedCPT-Cross-Encoder, Split=dev, Docs=50, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:32<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=ncbi/MedCPT-Cross-Encoder, Split=dev, Docs=50, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:32<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=foochun/bge-reranker-ft, Split=dev, Docs=20, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:45<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=foochun/bge-reranker-ft, Split=dev, Docs=20, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [00:46<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=foochun/bge-reranker-ft, Split=dev, Docs=30, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:03<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=foochun/bge-reranker-ft, Split=dev, Docs=30, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:04<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=foochun/bge-reranker-ft, Split=dev, Docs=50, Preprocessing=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:35<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n",
      "Running: Model=foochun/bge-reranker-ft, Split=dev, Docs=50, Preprocessing=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 200/200 [01:35<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "models = [\n",
    "    'cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
    "    'cross-encoder/ms-marco-MiniLM-L-12-v2',\n",
    "    'cross-encoder/ms-marco-TinyBERT-L-6',\n",
    "    'cross-encoder/ms-marco-electra-base',\n",
    "    'cross-encoder/stsb-roberta-base',\n",
    "    'BAAI/bge-reranker-base',\n",
    "    'BAAI/bge-reranker-large',\n",
    "    'ncbi/MedCPT-Cross-Encoder',\n",
    "    'foochun/bge-reranker-ft'\n",
    "]\n",
    "\n",
    "\n",
    "data_splits = [\n",
    "    #('train', df_query_train),\n",
    "    ('dev', df_query_dev)\n",
    "]\n",
    "\n",
    "n_docs_retrieved = [20, 30, 50]\n",
    "preprocessing_options = [False, True]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Loop over all config combinations\n",
    "for model, (split_name, df_query), n_docs, preprocessing in itertools.product(\n",
    "    models, data_splits, n_docs_retrieved, preprocessing_options\n",
    "):\n",
    "    print(f\"Running: Model={model}, Split={split_name}, Docs={n_docs}, Preprocessing={preprocessing}\")\n",
    "    \n",
    "    try:\n",
    "        results, submission_df, bm25_docs = run_experiment(\n",
    "            df_query, df_collection, model, n_docs, preprocessing=preprocessing\n",
    "        )\n",
    "        mrr_scores = evaluate(submission_df, results, 'label', 'preds') \n",
    "\n",
    "        mrr_scores = {f\"MRR@{k}\": v for k, v in mrr_scores.items()}\n",
    "\n",
    "        all_results.append({\n",
    "            'Model': model,\n",
    "            'Split': split_name,\n",
    "            'N_Docs': n_docs,\n",
    "            'Preprocessing': preprocessing,\n",
    "            **mrr_scores\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error: {e} | Config: Model={model}, Split={split_name}, Docs={n_docs}, Preprocessing={preprocessing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tabulate in /opt/conda/lib/python3.11/site-packages (0.9.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m| Model                                 | Split   |   N_Docs | Preprocessing   |   MRR@1 |    MRR@5 |   MRR@10 |\n",
      "|:--------------------------------------|:--------|---------:|:----------------|--------:|---------:|---------:|\n",
      "| cross-encoder/ms-marco-MiniLM-L-6-v2  | dev     |       20 | False           |   0.61  | 0.642583 | 0.642583 |\n",
      "| cross-encoder/ms-marco-MiniLM-L-6-v2  | dev     |       20 | True            |   0.61  | 0.642583 | 0.642583 |\n",
      "| cross-encoder/ms-marco-MiniLM-L-6-v2  | dev     |       30 | False           |   0.62  | 0.653667 | 0.653667 |\n",
      "| cross-encoder/ms-marco-MiniLM-L-6-v2  | dev     |       30 | True            |   0.62  | 0.653667 | 0.653667 |\n",
      "| cross-encoder/ms-marco-MiniLM-L-6-v2  | dev     |       50 | False           |   0.62  | 0.654667 | 0.654667 |\n",
      "| cross-encoder/ms-marco-MiniLM-L-6-v2  | dev     |       50 | True            |   0.62  | 0.654667 | 0.654667 |\n",
      "| cross-encoder/ms-marco-MiniLM-L-12-v2 | dev     |       20 | False           |   0.63  | 0.654917 | 0.654917 |\n",
      "| cross-encoder/ms-marco-MiniLM-L-12-v2 | dev     |       20 | True            |   0.63  | 0.654917 | 0.654917 |\n",
      "| cross-encoder/ms-marco-MiniLM-L-12-v2 | dev     |       30 | False           |   0.635 | 0.665583 | 0.665583 |\n",
      "| cross-encoder/ms-marco-MiniLM-L-12-v2 | dev     |       30 | True            |   0.635 | 0.665583 | 0.665583 |\n",
      "| cross-encoder/ms-marco-MiniLM-L-12-v2 | dev     |       50 | False           |   0.635 | 0.665583 | 0.665583 |\n",
      "| cross-encoder/ms-marco-MiniLM-L-12-v2 | dev     |       50 | True            |   0.635 | 0.665583 | 0.665583 |\n",
      "| cross-encoder/ms-marco-TinyBERT-L-6   | dev     |       20 | False           |   0.585 | 0.641333 | 0.641333 |\n",
      "| cross-encoder/ms-marco-TinyBERT-L-6   | dev     |       20 | True            |   0.585 | 0.641333 | 0.641333 |\n",
      "| cross-encoder/ms-marco-TinyBERT-L-6   | dev     |       30 | False           |   0.58  | 0.641083 | 0.641083 |\n",
      "| cross-encoder/ms-marco-TinyBERT-L-6   | dev     |       30 | True            |   0.58  | 0.641083 | 0.641083 |\n",
      "| cross-encoder/ms-marco-TinyBERT-L-6   | dev     |       50 | False           |   0.575 | 0.630667 | 0.630667 |\n",
      "| cross-encoder/ms-marco-TinyBERT-L-6   | dev     |       50 | True            |   0.575 | 0.630667 | 0.630667 |\n",
      "| cross-encoder/ms-marco-electra-base   | dev     |       20 | False           |   0.58  | 0.62325  | 0.62325  |\n",
      "| cross-encoder/ms-marco-electra-base   | dev     |       20 | True            |   0.58  | 0.62325  | 0.62325  |\n",
      "| cross-encoder/ms-marco-electra-base   | dev     |       30 | False           |   0.595 | 0.638    | 0.638    |\n",
      "| cross-encoder/ms-marco-electra-base   | dev     |       30 | True            |   0.595 | 0.638    | 0.638    |\n",
      "| cross-encoder/ms-marco-electra-base   | dev     |       50 | False           |   0.595 | 0.633667 | 0.633667 |\n",
      "| cross-encoder/ms-marco-electra-base   | dev     |       50 | True            |   0.595 | 0.633667 | 0.633667 |\n",
      "| cross-encoder/stsb-roberta-base       | dev     |       20 | False           |   0.215 | 0.323917 | 0.323917 |\n",
      "| cross-encoder/stsb-roberta-base       | dev     |       20 | True            |   0.215 | 0.323917 | 0.323917 |\n",
      "| cross-encoder/stsb-roberta-base       | dev     |       30 | False           |   0.19  | 0.27925  | 0.27925  |\n",
      "| cross-encoder/stsb-roberta-base       | dev     |       30 | True            |   0.19  | 0.27925  | 0.27925  |\n",
      "| cross-encoder/stsb-roberta-base       | dev     |       50 | False           |   0.16  | 0.236917 | 0.236917 |\n",
      "| cross-encoder/stsb-roberta-base       | dev     |       50 | True            |   0.16  | 0.236917 | 0.236917 |\n",
      "| BAAI/bge-reranker-base                | dev     |       20 | False           |   0.62  | 0.65625  | 0.65625  |\n",
      "| BAAI/bge-reranker-base                | dev     |       20 | True            |   0.62  | 0.65625  | 0.65625  |\n",
      "| BAAI/bge-reranker-base                | dev     |       30 | False           |   0.625 | 0.664583 | 0.664583 |\n",
      "| BAAI/bge-reranker-base                | dev     |       30 | True            |   0.625 | 0.664583 | 0.664583 |\n",
      "| BAAI/bge-reranker-base                | dev     |       50 | False           |   0.625 | 0.662417 | 0.662417 |\n",
      "| BAAI/bge-reranker-base                | dev     |       50 | True            |   0.625 | 0.662417 | 0.662417 |\n",
      "| BAAI/bge-reranker-large               | dev     |       20 | False           |   0.62  | 0.665917 | 0.665917 |\n",
      "| BAAI/bge-reranker-large               | dev     |       20 | True            |   0.62  | 0.665917 | 0.665917 |\n",
      "| BAAI/bge-reranker-large               | dev     |       30 | False           |   0.625 | 0.672417 | 0.672417 |\n",
      "| BAAI/bge-reranker-large               | dev     |       30 | True            |   0.625 | 0.672417 | 0.672417 |\n",
      "| BAAI/bge-reranker-large               | dev     |       50 | False           |   0.63  | 0.672    | 0.672    |\n",
      "| BAAI/bge-reranker-large               | dev     |       50 | True            |   0.63  | 0.672    | 0.672    |\n",
      "| ncbi/MedCPT-Cross-Encoder             | dev     |       20 | False           |   0.61  | 0.649583 | 0.649583 |\n",
      "| ncbi/MedCPT-Cross-Encoder             | dev     |       20 | True            |   0.61  | 0.649583 | 0.649583 |\n",
      "| ncbi/MedCPT-Cross-Encoder             | dev     |       30 | False           |   0.625 | 0.665417 | 0.665417 |\n",
      "| ncbi/MedCPT-Cross-Encoder             | dev     |       30 | True            |   0.625 | 0.665417 | 0.665417 |\n",
      "| ncbi/MedCPT-Cross-Encoder             | dev     |       50 | False           |   0.62  | 0.661833 | 0.661833 |\n",
      "| ncbi/MedCPT-Cross-Encoder             | dev     |       50 | True            |   0.62  | 0.661833 | 0.661833 |\n",
      "| foochun/bge-reranker-ft               | dev     |       20 | False           |   0.6   | 0.645167 | 0.645167 |\n",
      "| foochun/bge-reranker-ft               | dev     |       20 | True            |   0.6   | 0.645167 | 0.645167 |\n",
      "| foochun/bge-reranker-ft               | dev     |       30 | False           |   0.605 | 0.649583 | 0.649583 |\n",
      "| foochun/bge-reranker-ft               | dev     |       30 | True            |   0.605 | 0.649583 | 0.649583 |\n",
      "| foochun/bge-reranker-ft               | dev     |       50 | False           |   0.605 | 0.647833 | 0.647833 |\n",
      "| foochun/bge-reranker-ft               | dev     |       50 | True            |   0.605 | 0.647833 | 0.647833 |\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install tabulate\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "print(results_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the best model on the Train Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here compare the top 2 perfoming models on the full trainset: 'MedCPT-Cross-Encoder' and 'ms-marco-MiniLM-L-12-v2'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ms-marco-MiniLM-L-12-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 12853/12853 [39:14<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.5634482222049327, 5: 0.61377369745066, 10: 0.61377369745066}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results, submission_df, bm25_docs = run_experiment(df_query_train, df_collection, 'cross-encoder/ms-marco-MiniLM-L-12-v2', 30, preprocessing=False)\n",
    "evaluate(submission_df, results, 'label', 'preds') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MedCPT-Cross-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, submission_df, bm25_docs = run_experiment(df_query_train, df_collection, 'ncbi/MedCPT-Cross-Encoder', 30, preprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.5582354314167899, 5: 0.6161414974454732, 10: 0.6161414974454732}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(submission_df, results, 'label', 'preds') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the ms-marco-MiniLM-L-12-v2 model, as it is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('submission_train.tsv', sep = '\\t')\n",
    "results = pd.read_csv('results_df_train.tsv', sep = '\\t')\n",
    "bm25_docs = pd.read_csv('bm25_docs_train.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set label to one for all rows, since the cord-uid represents our positive sample\n",
    "training_data = df_query_train.copy()\n",
    "training_data['label'] = 1\n",
    "training_data.drop(['post_id'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep a reference of the docs-cord_uids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = df_collection[['title', 'abstract', 'cord_uid']].copy()\n",
    "\n",
    "all_docs['text'] = all_docs[['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1)\n",
    "all_docs.drop(['title', 'abstract'], axis= 1)\n",
    "\n",
    "cord_to_text = dict(zip(all_docs['cord_uid'], all_docs['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose samples as negatives from BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the reranking train data, add negative document samples from BM25 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranking_data = []\n",
    "\n",
    "for _, row in df_query_train.iterrows():\n",
    "    query = row['tweet_text']\n",
    "    true_doc_id = row['cord_uid']\n",
    "\n",
    "    pred_list = bm25_docs[row['post_id'] == bm25_docs['post_id']]['preds'].values #.tolist()\n",
    "    pred_list = pred_list[0]\n",
    "    \n",
    "    reranking_data.append((query, true_doc_id, 1))\n",
    "\n",
    "    hard_negatives = random.sample([doc_id for doc_id in pred_list if doc_id != true_doc_id], k=5)\n",
    "    \n",
    "    for neg_doc_id in hard_negatives:\n",
    "        reranking_data.append((query, neg_doc_id, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranking_data = [\n",
    "    (query, cord_to_text[cord_uid], label)\n",
    "    for query, cord_uid, label in reranking_data\n",
    "    if cord_uid in cord_to_text  # Skip if cord_uid not found\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = [\n",
    "    {\"text1\": query, \"text2\": doc, \"label\": label}\n",
    "    for query, doc, label in reranking_data\n",
    "]\n",
    "\n",
    "hf_train_dataset = Dataset.from_list(train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 1400/1400 [04:15<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n"
     ]
    }
   ],
   "source": [
    "results, submission_df, bm25_docs = run_experiment(df_query_dev, df_collection, 'cross-encoder/ms-marco-MiniLM-L-12-v2', 30, preprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.58, 5: 0.6261071428571429, 10: 0.6261071428571429}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dev set performance\n",
    "evaluate(submission_df, results, 'label', 'preds') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_query_dev.iterrows():\n",
    "    query = row['tweet_text']\n",
    "    true_doc_id = row['cord_uid']\n",
    "\n",
    "    pred_list = bm25_docs[row['post_id'] == bm25_docs['post_id']]['preds'].values #.tolist()\n",
    "    pred_list = pred_list[0]\n",
    "    \n",
    "    reranking_data.append((query, true_doc_id, 1))\n",
    "    \n",
    "    hard_negatives = [doc_id for doc_id in pred_list if doc_id != true_doc_id][:5]\n",
    "    \n",
    "    for neg_doc_id in hard_negatives:\n",
    "        reranking_data.append((query, neg_doc_id, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = df_query_dev.copy()\n",
    "eval_data['label'] = 1\n",
    "eval_data.drop(['post_id'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_samples = []\n",
    "\n",
    "for _, row in df_query_dev.iterrows():\n",
    "    query = row['tweet_text']\n",
    "    true_doc_id = row['cord_uid']\n",
    "\n",
    "    pred_list = bm25_docs[row['post_id'] == bm25_docs['post_id']]['preds'].values\n",
    "    pred_list = pred_list[0] \n",
    " \n",
    "    top_k_docs = pred_list[:5] \n",
    "    \n",
    "    if true_doc_id in top_k_docs:\n",
    "        top_k_docs.remove(true_doc_id)\n",
    "    top_k_docs = top_k_docs[:4]\n",
    "    \n",
    "    documents = [cord_to_text.get(doc_id, \"[MISSING]\") for doc_id in top_k_docs]\n",
    "    \n",
    "    eval_samples.append({\n",
    "        \"query\": query,\n",
    "        \"positive\": cord_to_text.get(true_doc_id),\n",
    "        \"documents\": documents,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-12-v2\", num_labels=1, max_length= 512)\n",
    "evaluator = CrossEncoderRerankingEvaluator(eval_samples, name='eval_devset2', show_progress_bar=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4820' max='4820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4820/4820 19:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Devset2 Map</th>\n",
       "      <th>Devset2 Mrr@10</th>\n",
       "      <th>Devset2 Ndcg@10</th>\n",
       "      <th>Devset2 Base Map</th>\n",
       "      <th>Devset2 Base Mrr@10</th>\n",
       "      <th>Devset2 Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.852024</td>\n",
       "      <td>0.852024</td>\n",
       "      <td>0.888962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.844607</td>\n",
       "      <td>0.844607</td>\n",
       "      <td>0.883331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.839738</td>\n",
       "      <td>0.839738</td>\n",
       "      <td>0.879791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.259500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.865429</td>\n",
       "      <td>0.865429</td>\n",
       "      <td>0.899213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.863810</td>\n",
       "      <td>0.863810</td>\n",
       "      <td>0.897968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.864774</td>\n",
       "      <td>0.864774</td>\n",
       "      <td>0.898622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.222900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.888393</td>\n",
       "      <td>0.888393</td>\n",
       "      <td>0.916543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.209400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.895595</td>\n",
       "      <td>0.895595</td>\n",
       "      <td>0.921924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.889750</td>\n",
       "      <td>0.889750</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.886190</td>\n",
       "      <td>0.886190</td>\n",
       "      <td>0.914812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.887321</td>\n",
       "      <td>0.887321</td>\n",
       "      <td>0.915749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.890714</td>\n",
       "      <td>0.890714</td>\n",
       "      <td>0.918276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4820, training_loss=0.23386955894375244, metrics={'train_runtime': 1175.3291, 'train_samples_per_second': 65.614, 'train_steps_per_second': 4.101, 'total_flos': 0.0, 'train_loss': 0.23386955894375244, 'epoch': 1.0})"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = CrossEncoderTrainingArguments(\n",
    "    output_dir=\"ms-marco-MiniLM-L-6-v2_train_2\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_ratio=0.1, \n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=400,\n",
    "    logging_steps=400,          \n",
    "    save_steps=400,\n",
    "    run_name=\"cross-encoder/ms-marco-MiniLM-L-12-v2\", \n",
    "    seed= 142\n",
    ")\n",
    "\n",
    "\n",
    "trainer = CrossEncoderTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=hf_train_dataset,\n",
    "\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./finetuned_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 1446/1446 [04:14<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.tsv\n",
      "Submission file saved to results_df.tsv\n",
      "Submission file saved to bm25_docs.tsv\n"
     ]
    }
   ],
   "source": [
    "results, submission_df, bm25_docs = run_experiment(df_query_test, df_collection, 'cross-encoder/ms-marco-MiniLM-L-12-v2', 30, preprocessing=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04596c26cfb0488e9474bd0247281fe4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06b3515e3ad4474588c510163c9bd059": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9df3f8fd0f84557818deaece92d472d",
      "max": 711396,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8d932c59601d4aecb17cf39ba93badcc",
      "value": 711396
     }
    },
    "0cfad64b3087458a8dca0c5915b3d8c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_954dfb7c8fbe4a059e6b18a4cd436caa",
      "max": 1330,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_738e5423a21646a6a60ea6f26750cef9",
      "value": 1330
     }
    },
    "0d33d8e45e5b450082988cffb9a908d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fb6caea0b3e4df786012ccdb451f4ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "106f1976a2584de9ab624c1ddb51dcc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18e45631ccbd4dd992380c3004e9d327",
      "placeholder": "​",
      "style": "IPY_MODEL_485ac50206f04d50964f66402ce6ac18",
      "value": " 232k/232k [00:00&lt;00:00, 2.39MB/s]"
     }
    },
    "17cca2ac93d1485bba92e61e3e9e49b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18e45631ccbd4dd992380c3004e9d327": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c6f09d38210407ca9290d71fba7d47b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d039a129ada49f39e748affd8f8fe91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d33d8e45e5b450082988cffb9a908d8",
      "placeholder": "​",
      "style": "IPY_MODEL_37376c1135d7417fba241373a5007d42",
      "value": " 1.33k/1.33k [00:00&lt;00:00, 112kB/s]"
     }
    },
    "24ef499ebfb64cc696ca4a17741f90af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2db29d42ece54241bf573331a9326685": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c13efe66574a4531bf0cb833744cff5d",
      "max": 132,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a986e1f3c12c44aa863a2d3ce25f7e7d",
      "value": 132
     }
    },
    "307011aa13004908a7ed2f024fa6e9f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a68a786b2e614f5e92206e7edfdecdcf",
      "placeholder": "​",
      "style": "IPY_MODEL_8be49307dca0423fa6152e83c6838ad8",
      "value": "config.json: 100%"
     }
    },
    "3629619ec44542b3beed4812a7ebe903": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7318c4dbc4ef4d5986e493060ad4cc68",
      "placeholder": "​",
      "style": "IPY_MODEL_0fb6caea0b3e4df786012ccdb451f4ae",
      "value": "vocab.txt: 100%"
     }
    },
    "36af8aca634142b4bccc6ed8cd264feb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6f2d02478a14ccf821caffe0ec32d68",
      "placeholder": "​",
      "style": "IPY_MODEL_477be68a6e8f47d5b19013a6a83441fc",
      "value": "model.safetensors: 100%"
     }
    },
    "37376c1135d7417fba241373a5007d42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e2d5f4f9a49469a811e966ebf04b26f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcbd65ca802644bc90207ac7b05ae5ba",
      "placeholder": "​",
      "style": "IPY_MODEL_7c30c9ea02d640828586d185e23990c1",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "407f985ef2d94b9087a3046178dc75fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "477be68a6e8f47d5b19013a6a83441fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "485ac50206f04d50964f66402ce6ac18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a436d340034431ca93052e8e4bcff7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aca246279a2847b4a73438a75ba2e41e",
      "placeholder": "​",
      "style": "IPY_MODEL_7b4e56c683a248898c20bf7ef9fe39fa",
      "value": " 794/794 [00:00&lt;00:00, 78.4kB/s]"
     }
    },
    "7318c4dbc4ef4d5986e493060ad4cc68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "738e5423a21646a6a60ea6f26750cef9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ac76d35a9ce4ef3a954e93f6774df99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d7ff5bb1968048288197cd5035a598f9",
       "IPY_MODEL_06b3515e3ad4474588c510163c9bd059",
       "IPY_MODEL_7b59fdfbc7584d84922c4047fe05728b"
      ],
      "layout": "IPY_MODEL_a9e57ed538ba4489a7173d1d807fb532"
     }
    },
    "7b4e56c683a248898c20bf7ef9fe39fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b59fdfbc7584d84922c4047fe05728b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96be80ee9865446d8f74a31718d7a26c",
      "placeholder": "​",
      "style": "IPY_MODEL_ecd6e8ba990c4cb1801b4a169454b43c",
      "value": " 711k/711k [00:00&lt;00:00, 7.82MB/s]"
     }
    },
    "7c30c9ea02d640828586d185e23990c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e37f77848f24e1baf2fc86195695f85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8748e94de96249b18e30dca020ea0ca3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_307011aa13004908a7ed2f024fa6e9f2",
       "IPY_MODEL_875f8677919549c3be9df86917fd12b0",
       "IPY_MODEL_4a436d340034431ca93052e8e4bcff7f"
      ],
      "layout": "IPY_MODEL_24ef499ebfb64cc696ca4a17741f90af"
     }
    },
    "875f8677919549c3be9df86917fd12b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96bf52ff2685433989f698fc5961ea9e",
      "max": 794,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e6c967af4c11487fba676a85d9dc188c",
      "value": 794
     }
    },
    "87e3f771e8f6431b83b980182e7ad260": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3629619ec44542b3beed4812a7ebe903",
       "IPY_MODEL_bed01a0af52146d9af8ae88428873582",
       "IPY_MODEL_106f1976a2584de9ab624c1ddb51dcc6"
      ],
      "layout": "IPY_MODEL_da6b7b183a4c4711bb716570adce272e"
     }
    },
    "8be49307dca0423fa6152e83c6838ad8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c1d68572b9a47dab9f92a58109c99e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d932c59601d4aecb17cf39ba93badcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "954dfb7c8fbe4a059e6b18a4cd436caa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96be80ee9865446d8f74a31718d7a26c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96bf52ff2685433989f698fc5961ea9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a68a786b2e614f5e92206e7edfdecdcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a986e1f3c12c44aa863a2d3ce25f7e7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a9df3f8fd0f84557818deaece92d472d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9e57ed538ba4489a7173d1d807fb532": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa5e644f01ee4d3cbc8f1edc4d85b9da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aca246279a2847b4a73438a75ba2e41e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0aa5c62d74a47ad80e77009d72f943d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c377f3ea4ce444b187e978aff2a4dc61",
      "max": 90870598,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_407f985ef2d94b9087a3046178dc75fd",
      "value": 90870598
     }
    },
    "b18ecf5cdde94f57bf861c9454915b10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b86d096ad1c84d1fbca2e498a6c65d56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bed01a0af52146d9af8ae88428873582": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c6f09d38210407ca9290d71fba7d47b",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b18ecf5cdde94f57bf861c9454915b10",
      "value": 231508
     }
    },
    "c13efe66574a4531bf0cb833744cff5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c377f3ea4ce444b187e978aff2a4dc61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb7da9ced8544596afe739ba3957e8fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04596c26cfb0488e9474bd0247281fe4",
      "placeholder": "​",
      "style": "IPY_MODEL_fb0fc7451d7f417fb03484108871666a",
      "value": " 132/132 [00:00&lt;00:00, 11.9kB/s]"
     }
    },
    "d026944f169049509f25e94618e25a1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_36af8aca634142b4bccc6ed8cd264feb",
       "IPY_MODEL_b0aa5c62d74a47ad80e77009d72f943d",
       "IPY_MODEL_fda8b86317224c19b277b7f56bd22dfe"
      ],
      "layout": "IPY_MODEL_f03d1ccd36184ae88ff3f9c52722a566"
     }
    },
    "d330ae25165b445ba299e88873d7f399": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6f2d02478a14ccf821caffe0ec32d68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7ff5bb1968048288197cd5035a598f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df9c4ac305a04b88a79bca22b86457f4",
      "placeholder": "​",
      "style": "IPY_MODEL_8c1d68572b9a47dab9f92a58109c99e0",
      "value": "tokenizer.json: 100%"
     }
    },
    "da6b7b183a4c4711bb716570adce272e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcbd65ca802644bc90207ac7b05ae5ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dec3fd984f3445648d09a138919a801e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df9c4ac305a04b88a79bca22b86457f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6c967af4c11487fba676a85d9dc188c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ecd6e8ba990c4cb1801b4a169454b43c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f03d1ccd36184ae88ff3f9c52722a566": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f18d56a108a54f01b0c3eea8471a8cbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e37f77848f24e1baf2fc86195695f85",
      "placeholder": "​",
      "style": "IPY_MODEL_b86d096ad1c84d1fbca2e498a6c65d56",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "f526c2b1e4a344aab0dcb79d081a1bef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3e2d5f4f9a49469a811e966ebf04b26f",
       "IPY_MODEL_2db29d42ece54241bf573331a9326685",
       "IPY_MODEL_cb7da9ced8544596afe739ba3957e8fd"
      ],
      "layout": "IPY_MODEL_17cca2ac93d1485bba92e61e3e9e49b4"
     }
    },
    "fb0fc7451d7f417fb03484108871666a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc810673ded14b5986a45069b5fcc199": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f18d56a108a54f01b0c3eea8471a8cbc",
       "IPY_MODEL_0cfad64b3087458a8dca0c5915b3d8c7",
       "IPY_MODEL_1d039a129ada49f39e748affd8f8fe91"
      ],
      "layout": "IPY_MODEL_d330ae25165b445ba299e88873d7f399"
     }
    },
    "fda8b86317224c19b277b7f56bd22dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dec3fd984f3445648d09a138919a801e",
      "placeholder": "​",
      "style": "IPY_MODEL_aa5e644f01ee4d3cbc8f1edc4d85b9da",
      "value": " 90.9M/90.9M [00:00&lt;00:00, 200MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
